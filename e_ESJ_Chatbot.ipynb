{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-J9EWz18c3y",
        "outputId": "a159d7ea-ec14-4b6f-928c-0e6eb332fa50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.24.7)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.36.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.35.13)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.6 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.24.6)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.4.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<5,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade PyMuPDF streamlit openai faiss-cpu\n",
        "import os\n",
        "import fitz\n",
        "import openai\n",
        "import faiss\n",
        "import numpy as np\n",
        "# PyMuPDF: for accessing PDF files, extracting text, images, and metadata, and performing various other operations on PDF documents.\n",
        "# streamlit: framework for creating interactive web applications for data science and machine learning.\n",
        "# openai: official Python client library for the OpenAI API.\n",
        "# faiss-cpu: FAISS (Facebook AI Similarity Search) is a library for efficient similarity search and clustering of dense vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extract Text from PDF**"
      ],
      "metadata": {
        "id": "AWuGQ7Sp8vcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder_path = '/content/drive/My Drive/pdfs/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAiGTWl08rpg",
        "outputId": "4fd3681e-ba59-4afa-c913-6e49bd500b26"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we'll be working with only the pdfs for now"
      ],
      "metadata": {
        "id": "IvR0gthE85np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"fitz is a Python binding for the MuPDF library, which allows you to work with PDF files. \"\"\"\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    document = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page_num in range(len(document)):\n",
        "        page = document.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "# extracts text from each page of a PDF and concatenate it into a single string.\n",
        "# List all PDF files in the folder\n",
        "\n",
        "pdf_files = os.listdir(folder_path)\n",
        "pdf_paths = [os.path.join(folder_path, pdf_file) for pdf_file in pdf_files if pdf_file.endswith('.pdf')]\n",
        "pdf_text=\"\"\n",
        "# Extract text from each PDF\n",
        "for pdf_path in pdf_paths:\n",
        "    pdf_text += extract_text_from_pdf(pdf_path)\n",
        "    print(f\"PDF: {pdf_path} extracted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "CDdONSar85VX",
        "outputId": "d3922aba-3e44-48da-862a-b1cf084fe032"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF: /content/drive/My Drive/pdfs/Berrada Karim .pdf extracted\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-01b21f1286b2>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Extract text from each PDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpdf_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpdf_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpdf_text\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"PDF: {pdf_path} extracted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-01b21f1286b2>\u001b[0m in \u001b[0;36mextract_text_from_pdf\u001b[0;34m(pdf_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpage_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# extracts text from each page of a PDF and concatenate it into a single string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymupdf/utils.py\u001b[0m in \u001b[0;36mget_text\u001b[0;34m(page, option, clip, flags, textpage, sort, delimiters)\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[0;31m#pymupdf.exception_info()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m         \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_textpage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"parent\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"not a textpage of this page\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymupdf/__init__.py\u001b[0m in \u001b[0;36mget_textpage\u001b[0;34m(self, clip, flags, matrix)\u001b[0m\n\u001b[1;32m   9235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9236\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9237\u001b[0;31m             \u001b[0mtextpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_textpage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9238\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9239\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mold_rotation\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymupdf/__init__.py\u001b[0m in \u001b[0;36m_get_textpage\u001b[0;34m(self, clip, flags, matrix)\u001b[0m\n\u001b[1;32m   7758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_textpage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mg_use_extra\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7760\u001b[0;31m             \u001b[0mll_tpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_get_textpage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7761\u001b[0m             \u001b[0mtpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmupdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFzStextPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mll_tpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtpage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymupdf/extra.py\u001b[0m in \u001b[0;36mpage_get_textpage\u001b[0;34m(_self, clip, flags, matrix)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpage_get_textpage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_extra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_get_textpage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mJM_make_textpage_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Index the Extracted Text**"
      ],
      "metadata": {
        "id": "FwQpG5BM9AK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#openai.api_key = os.environ['sk-proj-q8SIAXcn3SQjIfM25mcLT3BlbkFJw4llMBxOTLm2R7b4Y1cv']\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key='sk-proj-q8SIAXcn3SQjIfM25mcLT3BlbkFJw4llMBxOTLm2R7b4Y1cv',\n",
        ")"
      ],
      "metadata": {
        "id": "CU0pJUQkCKT2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key directly\n",
        "openai.api_key = \"sk-proj-q8SIAXcn3SQjIfM25mcLT3BlbkFJw4llMBxOTLm2R7b4Y1cv\"\n",
        "def get_openai_embeddings(text_list):\n",
        "    embeddings = []\n",
        "    for text in text_list:\n",
        "        response = client.embeddings.create(input=text, model=\"text-embedding-3-small\").data[0].embedding\n",
        "        embeddings.append(response)\n",
        "    return embeddings\n",
        "def index(name):\n",
        "    corpus_text = pdf_text\n",
        "    corpus_chunks = corpus_text.split('\\n')  # Split the text into chunks based on newline characters\n",
        "    # Generate embeddings using OpenAI API\n",
        "    corpus_embeddings = get_openai_embeddings(corpus_chunks)\n",
        "    # Convert embeddings to numpy array\n",
        "    corpus_embeddings = np.array(corpus_embeddings)\n",
        "    # Create and populate the FAISS index\n",
        "    index = faiss.IndexFlatL2(corpus_embeddings.shape[1])\n",
        "    index.add(corpus_embeddings)\n",
        "    # Save the index\n",
        "    faiss.write_index(index, f'{name}.faiss')\n",
        "    # Save the chunks\n",
        "    with open(f'{name}_chunks.txt', 'w') as f:\n",
        "      for chunk in corpus_chunks:\n",
        "        f.write(f\"{chunk}\\n\")\n"
      ],
      "metadata": {
        "id": "TvbkESjW89ov"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Retrieve Relevant Information**"
      ],
      "metadata": {
        "id": "clAw18um9Riz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_relevant_chunks(query, index, chunks, k ):\n",
        "    \"\"\"K is The number of relevant chunks to retrieve\"\"\"\n",
        "    query_embedding = get_openai_embeddings([query])\n",
        "    query_embedding = np.array(query_embedding)\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "    relevant_chunks = [chunks[idx] for idx in indices[0]]\n",
        "    return relevant_chunks"
      ],
      "metadata": {
        "id": "czVVzF6d9SAi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Integrate with OpenAI GPT-4**"
      ],
      "metadata": {
        "id": "y7mzX02D9inY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stackoverflow.com/questions/75774873/openai-api-error-this-is-a-chat-model-and-not-supported-in-the-v1-completions\n",
        "\n",
        "\n",
        "https://stackoverflow.com/questions/77469966/openai-api-error-you-tried-to-access-openai-completion-but-this-is-no-longer"
      ],
      "metadata": {
        "id": "JGvjkxXZH33O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the FAISS index and the corpus chunks\n",
        "Corpus_name = 'DATA'  # Replace with your actual corpus name\n",
        "index(Corpus_name)\n",
        "\n",
        "# Load the corpus chunks\n",
        "with open(f'{Corpus_name}_chunks.txt', 'r') as f:\n",
        "    corpus_chunks = f.read().splitlines()\n",
        "\n",
        "# Load the corpus index\n",
        "corpus_index = faiss.read_index(f'{Corpus_name}.faiss')\n",
        "\n",
        "# Define context\n",
        "context = (\n",
        "    \"\"\"Task: I want you to answer the questions of doctors concerning medical knowledge and patient information. Identify symptoms and provide potential diagnoses along with prescription of Moroccan medication. Specify at the end that your suggestions are not 100% accurate and must be validated by a healthcare professional.\n",
        "Persona: You are an expert in healthcare, both physical and mental. You are familiar with Moroccan medication and will only prescribe those. Respond in the language of the question.\n",
        "\n",
        "Format:\n",
        "- Use the language of the query to formulate your response.\n",
        "- Provide concise responses related to the user's prompts, limited to 4 lines in clear bullet points unless more detail is requested.\n",
        "- If more detailed information is requested, elaborate up to 1000 lines.\n",
        "\n",
        "Tone:\n",
        "- Maintain a professional yet friendly tone.\n",
        "- Use clear and elegant language.\n",
        "\n",
        "Reminder:\n",
        "Always specify at the end of your response that the provided suggestions are not definitive and should not be acted upon without the supervision of a healthcare professional.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Function to get a response from GPT-4\n",
        "def get_response(query):\n",
        "    # Retrieve relevant chunks\n",
        "    relevant_chunks = retrieve_relevant_chunks(query, corpus_index, corpus_chunks, 3)\n",
        "    # Combine the relevant chunks into the prompt\n",
        "    rag_prompt = context + \"\\n\\n\" + \"\\n\\n\".join(relevant_chunks) + \"\\n\\nQ: \" + query + \"\\nA:\"\n",
        "    response = \topenai.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "        {\"role\": \"assistant\", \"content\": rag_prompt},\n",
        "        ],\n",
        "        #prompt=rag_prompt,\n",
        "        max_tokens=500,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# Chat function\n",
        "def chat():\n",
        "    print(\"üí¨ Healthcare Chatbot\")\n",
        "    print(\"Welcome to the e-ESJ Chatbot! Use this tool to search patient information or enter the patient's symptoms and medical history to receive a potential diagnosis along with medication suggestions.\")\n",
        "    print(\"Type 'exit' to end the chat.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "        response = get_response(user_input)\n",
        "        print(f\"Chatbot: {response}\")\n",
        "\n",
        "# Start the chat\n",
        "chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBfJJH9E9i8H",
        "outputId": "5abd40f1-fa5e-4a2c-f684-49132410f6a1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üí¨ Healthcare Chatbot\n",
            "Welcome to the e-ESJ Chatbot! Use this tool to search patient information or enter the patient's symptoms and medical history to receive a potential diagnosis along with medication suggestions.\n",
            "Type 'exit' to end the chat.\n",
            "You: hi\n",
            "Chatbot: Hello! How can I assist you today?\n",
            "You: I wanted to know more about Parkinson's disease\n",
            "Chatbot: - La maladie de Parkinson est une maladie neurologique progressive qui affecte le mouvement.\n",
            "- Elle est caract√©ris√©e par des sympt√¥mes tels que des tremblements, une rigidit√©, des probl√®mes de coordination et d'√©quilibre.\n",
            "- En Maroc, on peut prescrire des m√©dicaments tels que la L√©vodopa ou les agonistes de la dopamine pour aider √† contr√¥ler les sympt√¥mes.\n",
            "- Cependant, il faut noter que ces suggestions ne sont pas 100% pr√©cises et doivent √™tre valid√©es par un professionnel de la sant√©.\n",
            "You: exit\n"
          ]
        }
      ]
    }
  ]
}